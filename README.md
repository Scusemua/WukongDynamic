# Wukong Divide-and-Conquer

Wukong Divide-and-Conquer (aka Wukong Dynamic) is an attempt to realize a fully-generic serverless execution engine.

Built as a conceptual extension of the original Wukong project, Wukong DnC provides a generic programming model, enabling the execution of arbitrary workloads.

To run code in this library, set your working directory to be `DivideAndConquer/`. Then, you can run the driver programs as follows:
```
python mergesort_driver.py -h
python treereduction_driver.py -h
python fibonnaci_driver.py -h
```

<!---```
<>python -m wukongdnc.mergesort_driver -h
<>python -m wukongdnc.treereduction_driver -h
<>python -m wukongdnc.fibonnaci_driver -h
<>-->

## The TCP Server

This framework requires you have a Redis server available (although Redis is not used.)
The IP address should be specified in `DivideAndConquer/wukongdnc/constants.py`. Likewise, the TCP server defined in `DivideAndConquer/wukongdnc/tcp_server.py` must 
be running as well (and its IP address should be set in the aforementioned `constants.py` file). Finally, an AWS Lambda function must be configured and contain all of the code except the `coordinator/` directory, `data/` directory, and `programs/` directory.

### Running the TCP Server

The TCP server can be started by setting your working directory to be `DivideAndConquer/` and then executing the following command: 
`python -m wukongdnc.server.tcp_server`

The TCP server that uses synchronization objects stored in AWS Lambda functions can be started similarly. Set your working directory to be `DivideAndConquer/` and execute the following command:
`python -m wukongdnc.server.tcp_server_lambda`

## Running the Dask DAG Experiments

The configuration parameters are in DAG_executor_constants.py. There you can configurefor workers threads or processes or Lambdas (real or simulated), non-pagerank DAG
execution (i.e., Dask DAGS), pagerank DAGs, and a host of other parameters. DAG_executor_constants defines tests
that exerciss the various parameters and illustrates the most likely configurations. See TestAll.py for a procedure to 
run a test. It also descripts a PowerShell script for running
all of the tests one-by-one (hitting enter between tests).

To generate the necessary DAG_info.pickle file for non-pagerank DAGs first edit wukongdnc.dag.dask_dag and uncomment the name of the program you want to generate 
a DAG for. Then execute the following command:

`python -m wukongdnc.dag.dask_dag`

This creates a DAG_info.pickle file that is read by the DAG_executor_driver
and workers. (Actually, dask_dag generates a file foo, e.g., DAG_info-manual_dag.pickle, and we copy foo to DAG_info.pickle.) DAG_info.pickle contains a 
representation of the DAG.

[
dask_dag has "Dask programs" like:
def manual_dag():
    print("==== GENERATING MANUALLY-CREATED DAG")
    inc0 = dask.delayed(increment)(0) # 1
    inc1 = dask.delayed(increment)(1) # 2
    trip = dask.delayed(triple)(inc1) # 6
    sq = dask.delayed(square)(inc1) # 4
    ad = dask.delayed(add)(inc1, inc0) # 1+2 = 3
    mult = dask.delayed(multiply)(trip, sq, ad)  # 6*4*3 = 72
    div = dask.delayed(divide)(mult) # 72 / 72 = 1.0

    graph = div.__dask_graph__()
    result = div.compute()

    return graph, result

The DAG is saved in a DAG_info.pickle file that is input when the DAG is excuted.

You can select a program to generate a DAG for by uncommenting the one you want:
  graph, result = manual_dag()
  # graph, result = manual_dag_test_batch_faninNBs()
  # graph, result = manual_dag_test_batch_two_faninNBs()
  # graph, result = manual_dag_no_faninNBs()
  # graph, result = tree_reduction(n = 1024)
  # graph, result = mat_mul(n = 4, c = 2)
]

Next, to run non-pagerank (Dask) DAGS, where the DAG_info.pickle file is  generated by dask_dag, execute the following commands (in order):
If the synch objects are stored remotely (as set in the DAG_excutor_constants.py  file) you must start the tcp_server first; othewise, tcp_server is not needed.
'python -m wukongdnc.server.tcp_server'
`python -m wukongdnc.dag.DAG_executor_driver`

Run pagerank DAGs with 

'python -m wukongdnc.dag.BFS'

where input_graph() in BFS.py inputs the selected graph file at the top of input_graph(). For example:

    fname = "graph_24N_3CC_fanin"   # 24 nodes, 3 connected components, fanin at end
    #fname = "graph_2N_2CC"         # 2 nodes (CCs) no edges
    #fname = "graph_3N_3CC"         # 3 nodes (CCs) no edges  
    ... etc         

BFS will generate the DAG_info.pickle file and call wukongdnc.dag.DAG_executor_driver() to execute it. If the synch objects are stored remotely, 
and/or you are using worker processes (in which case the sync objects must be stored
remotely) start the tcp_server first:

`python -m wukongdnc.server.tcp_server`

Note: To capture all output in windows DOS box: command > logfile 2>&1
(STDIN is file descriptor #0. STDOUT is file descriptor #1. STDERR is file descriptor #2. Just as "command > file" redirects STDOUT to a file, you may also redirect arbitrary file descriptors to each other. The ">&" operator redirects between file descriptors. So, "2 >& 1" redirects all STDERR output to STDOUT.)